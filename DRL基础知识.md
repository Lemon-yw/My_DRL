

# 神经网络

## 概念

**神经网络**是一种数学模型，是存在于计算机的神经系统，由大量的神经元相连接并进行计算，在外界信息的基础上，改变内部的结构，常用来对输入和输出间复杂的关系进行建模。

神经网络由大量的节点和之间的联系构成，负责传递信息和加工信息，神经元也可以通过训练而被强化。

![image-20200929111038039](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cidpowtj311w0l2e6i.jpg)

这个图就是一个神经网络系统，它由很多层构成：

* 输入层就是负责接收信息，比如说一只猫的图片。
* 隐藏层就是对输入信息的加工处理。
* 输出层就是计算机对这个输入信息的认知，它是不是猫。

## 神经网络的训练

1. 首先它需要很多数据。
   比如他要判断一张图片是不是猫。就要输入上千万张的带有标签的猫猫狗狗的图片，然后再训练上千万次。

2. 神经网络训练的结果有对的也有错的，如果是错误的结果，将被当做非常宝贵的经验，那么是**如何从经验中学习的呢？**
   就是对比正确答案和错误答案之间的区别，然后把这个区别**反向的传递**回去，对每个相应的神经元进行一点点的改变。那么下一次在训练的时候就可以用已经改进一点点的神经元去得到稍微准确一点的结果。

3. **神经网络是如何训练的呢？**每个神经元都有属于它的**激活函数**，用这些函数给计算机一个刺激行为。

   ![image-20200929111309354](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7ckzquwqj30wu0j4aus.jpg)

   在第一次给计算机看猫的图片的时候，只有部分的神经元被激活，被激活的神经元所传递的信息是对输出结果最有价值的信息。如果输出的结果被判定为是狗，也就是说是错误的了，那么就会修改神经元，一些容易被激活的神经元会变得迟钝，另外一些神经元会变得敏感。这样一次次的训练下去，所有神经元的参数都在被改变，它们变得对真正重要的信息更为敏感。

   ![image-20200929111503409](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cmzoln8j311y0jeh8g.jpg)

   ![image-20200929111523738](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cnbzv6pj311q0isaxd.jpg)

   代码及更多内容参考：https://www.jianshu.com/p/e112012a4b2d

## 卷积神经网络 CNN（Convolutional Neural Network）

卷积神经网络不再是对每个像素的输入信息做处理了，而是图片上每一小块像素区域进行处理，这种做法加强了图片信息的连续性，使得神经网络能看到图形，而非一个点。

这种做法同时也加深了神经网络对图片的理解。具体来说：

1. 卷积神经网络有一个批量过滤器，持续不断的在图片上滚动收集图片里的信息，每一次收集的时候都只是收集一小块像素区域，然后把收集来的信息进行整理，这时候整理出来的信息有了一些实际上的呈现，比如这时的神经网络能看到一些边缘的图片信息。
2. 然后再以同样的步骤，用类似的批量过滤器扫过产生的这些边缘信息，神经网络从这些边缘信息里面总结出更高层的信息结构，比如说总结的边缘能够画出眼睛，鼻子等等。
3. 再经过一次过滤，脸部的信息也从这些眼睛鼻子的信息中被总结出来。
4. 最后我们再把这些信息套入几层普通的全连接神经层进行分类，这样就能得到输入的图片能被分为哪一类的结果了。

![image-20200929113820427](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7db7koufj30wy0gg7bo.jpg)

具体说说图片是如何被卷积的。上面是一张猫的图片（以彩色照片为例）:

1. 过滤器就是影像中不断移动的东西，它不断在图片收集小批小批的像素块，收集完所有信息后，输出的值我们可以理解成是一个高度更高，长和宽更小的“图片”。这个图片里就能包含一些边缘信息。
2. 然后以同样的步骤再进行多次卷积，将图片的长宽再压缩，高度再增加，就有了对输入图片更深的理解。
3. 将压缩、增高的信息嵌套在普通的分类神经层上，我们就能对这种图片进行分类了。

> 图片有长，宽，高 三个参数。这里图片的高指的是计算机用于产生颜色使用的信息。如果是黑白照片的话，高的单位就只有1，如果是彩色照片，就可能有红绿蓝三种颜色的信息，这时的高度为3。

### 池化（pooling）

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7dib9elrj30lq0ciq6n.jpg" alt="image-20200929114510803" style="zoom:60%;" />

研究发现，在每一次卷积的时候，神经层可能会无意地丢失一些信息。这时，池化 (pooling) 就可以很好地解决这一问题。

**池化是一个筛选过滤的过程**，能将 layer 中有用的信息筛选出来，给下一个层分析。同时也减轻了神经网络的计算负担。也就是说在卷积的时候，我们不压缩长宽，尽量地保留更多信息，压缩的工作就交给池化了，这样的一项附加工作能够很有效的提高准确性。

## 循环神经网络 RNN（Recurrent Neural Network）

**RNN 是用来处理序列数据的神经网络**。那我们如何让数据间的关联被 NN 加以分析呢？

人类分析各种事物关联的最基本方式就是记住之前发生的事情。那我们让神经网络也具备这种记住之前发生的事的能力：

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7e9ibptvj30wo0guqpa.jpg" alt="image-20200929121118487" style="zoom:50%;" />

1. 在分析 Data0 的时候，我们把分析结果存入记忆。
2. 然后当分析 Data1 的时候，NN会产生新的记忆，但是新记忆和老记忆是没有联系的。我们就简单的把老记忆调用过来，一起分析。
3. 如果继续分析更多的有序数据，RNN就会把之前的记忆都累积起来，一起分析。

### LSTM RNN 循环神经网络（LSTM）

#### RNN 的弊端

之前我们说过，RNN 是在有顺序的数据上进行学习的。为了记住这些数据，RNN 会像人一样产生对先前发生事件的记忆。不过一般形式的 RNN 就像一个老爷爷，有时候比较健忘。为什么会这样呢？

具体原因参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/LSTM/

#### LSTM

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7ehfrgfij30sm0ni1kx.jpg" alt="image-20200929121855417" style="zoom:40%;" />

LSTM 就是为了解决这个问题而诞生的。LSTM 和普通 RNN 相比多出了三个控制器：输入控制、输出控制、忘记控制。 LSTM RNN 内部的情况如上图所示。

它多了一个 **控制全局的记忆**，我们用粗线代替。为了方便理解，我们把粗线想象成电影或游戏当中的 主线剧情，而原本的 RNN 体系就是 分线剧情。三个控制器都是在原始的 RNN 体系上。

1. 先看 输入方面：如果此时的分线剧情对于剧终结果十分重要，输入控制就会**将这个分线剧情按重要程度写入主线剧情进行分析**；
2. 再看 忘记方面：如果此时的分线剧情更改了我们对之前剧情的想法，那么忘记控制就会将之前的某些主线剧情忘记，按比例替换成现在的新剧情。所以**主线剧情的更新就取决于输入 和忘记 控制**。
3. 最后 输出方面：输出控制会**基于目前的主线剧情和分线剧情判断要输出的到底是什么**。

基于这些控制机制，LSTM 就像延缓记忆衰退的良药，可以带来更好的结果。

## 自编码（Autoencoder）

自编码是一种神经网络的形式，是用神经网络进行非监督形式的学习。

### 压缩与解压

有一个神经网络，它在做的事情是：接收一张图片，然后 给它打码，最后 再从打码后的图片中还原。

图片其实是经过了压缩，再解压的这一道工序。当压缩的时候，原有的图片质量被缩减，解压时用信息量小却包含了所有关键信息的文件恢复出原本的图片。为什么要这样做呢？

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7hym8wn5j30ww0hi1kx.jpg" alt="image-20200929141914201" style="zoom: 50%;" />

原因是：有时神经网络要接受大量的输入信息，比如输入信息是高清图片时，输入信息量可能达到上千万，让神经网络直接从上千万个信息源中学习是一件很吃力的工作。所以，何不压缩一下，提取出原图片中的最具代表性的信息，缩减输入信息量，再把缩减过后的信息放进神经网络学习。这样学习起来就简单轻松了。

所以，自编码就能在这时发挥作用。通过将原数据白色的X 压缩，解压 成黑色的X，然后通过对比黑白 X ,求出预测误差，进行反向传递，逐步提升自编码的准确性。训练好的自编码中间这一部分就是能总结原数据的精髓。可以看出，从头到尾，我们只用到了输入数据 X，并没有用到 X 对应的数据标签，所以也可以说自编码是一种非监督学习。到了真正使用自编码的时候. 通常只会用到自编码前半部分。



# 强化学习

## 机器学习、深度学习、强化学习、深度强化学习

![image-20200928233034231](https://tva1.sinaimg.cn/large/007S8ZIlly1gj6sa1q9i8j310k0j4k2p.jpg)

<u>机器学习</u>：一切通过优化方法挖掘数据中规律的学科。

<u>深度学习</u>：一切运用了神经网络作为参数结构进行优化的机器学习算法。

<u>强化学习</u>：不仅能利用现有数据，还可以通过对环境的探索获得新数据，并利用新数据循环往复地更新迭代现有模型的机器学习算法。学习是为了更好地对环境进行探索，而探索是为了获取数据进行更好的学习。

<u>深度强化学习</u>：一切运用了神经网络作为参数结构进行优化的强化学习算法。

从大的角度讲，**机器学习是包括深度学习和强化学习的**。

强化学习和深度学习的主要区别在于：

1. **深度学习的训练样本是有标签的，强化学习的训练是没有标签的**，它是通过环境给出的奖惩来学习；
2. **深度学习的学习过程是静态的，强化学习的学习过程是动态的**。这里静态与动态的区别在于是否会与环境进行交互，深度学习是给什么样本就学什么，而强化学习是要和环境进行交互，再通过环境给出的奖惩来学习；
3. **深度学习解决的更多是感知问题，强化学习解决的主要是决策问题**。因此有监督学习更像是五官，而强化学习更像大脑。

> 应用方面
>
> -- 较传统的机器学习（包括lr svm decision tree GBDT RF  etc.）多用于数据挖掘、数据分析和预测等领域；
> -- 深度学习最广泛的应用是图像处理和NLP了；
> -- 强化学习实际应用目前主要包括AI游戏（如Atari），推荐系统（如阿里家的），机器人控制相关（如Ng的无人机飞行）。

## 强化学习算法的分类

### 不理解环境(Model-Free RL) & 理解环境(Model-Based RL)

1. Model-Free RL

   不尝试去理解环境，环境给了我们什么就是什么。

2. Model-Based RL

   这里的model就是用模型来表示环境，理解了环境也就是学会了一个模型来代表环境。

> Model-Free 与 Model-Based 区别：
>
> 1. Model-Based 比 Model-Free 多了一个**虚拟环境**(为现实世界建模)
>
> 2. Model-Based 比 Model-Free 多了更多的**“想象力”**
>
>    Model-Free 只能一步一步等待真实世界的反馈，再根据反馈采取下一步的行动；
>
>    Model-Based 可以通过“想象”来预判到接下来发生的所有情况，然后根据想象中的情况选择最好的那种，并根据这种情况来采取下一步的策略。

### 基于概率(Policy-Based RL) & 基于价值(Value-Based RL)

1. Policy-Based RL

   通过分析所处环境，直接分析出下一步采取各种行动的概率，然后根据概率采取行动，所以所有动作都可以被选中，只是可能性不同。

2. Value-Based RL

   通过分析所处环境，直接分析出下一步采取各种行动的价值，然后根据最高价值采取行动。与Policy-Based 相比**决策更为确定**，只选价值最高的。

> 对于连续动作，无法基于价值(Value-Based)进行动作的选择，但是可以基于概率分布(Policy-Based)在连续的动作中选择特定的动作。

### 回合更新(Monte-Carlo update) & 单步更新(Temporal-Difference update)

1. Monte-Carlo update

   训练开始 -- > 训练结束 -- > 对该回合进行复盘与更新

2. Temporal-Difference update

   训练开始 -- > 单步更新  -- > 单步更新  -- > ... -- > 训练结束

### 在线学习(Online-Learning) & 离线学习(Offline-Learning)

1. Online-Learning

   一个数据点训练完了直接更新权重（而不是一个batch）。

   在线算法按照顺序处理数据，它们产生一个模型，并在把这个模型放入实际操作中，而**不需要在一开始就提供完整的的训练数据集。随着更多的实时数据到达，模型会在操作中不断地更新。**

2. Offline-Learning

   一个batch训练完才更新权重。

   在离线学习中，所有的训练数据在模型训练期间必须是可用的。只有训练完成了之后，模型才能被拿来用。简而言之，**先训练，再用模型，不训练完就不用模型。**

 对比图

<img src="https://img-blog.csdnimg.cn/2019110915213854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjI2NzYxNQ==,size_16,color_FFFFFF,t_70" alt="离线模式选择(左)与在线模式选择(右)" style="zoom: 80%;" />

> Online-Learning & Offline-Learning 也叫 On-Policy & Off-Policy
>
> 更多参考：https://blog.csdn.net/weixin_42267615/article/details/102973252?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf



更多参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/