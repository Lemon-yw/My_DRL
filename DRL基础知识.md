

# 神经网络

## 概念

**神经网络**是一种数学模型，是存在于计算机的神经系统，由大量的神经元相连接并进行计算，在外界信息的基础上，改变内部的结构，常用来对输入和输出间复杂的关系进行建模。

神经网络由大量的节点和之间的联系构成，负责传递信息和加工信息，神经元也可以通过训练而被强化。

![image-20200929111038039](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cidpowtj311w0l2e6i.jpg)

这个图就是一个神经网络系统，它由很多层构成：

* 输入层就是负责接收信息，比如说一只猫的图片。
* 隐藏层就是对输入信息的加工处理。
* 输出层就是计算机对这个输入信息的认知，它是不是猫。

## 神经网络的训练

1. 首先它需要很多数据。
   比如他要判断一张图片是不是猫。就要输入上千万张的带有标签的猫猫狗狗的图片，然后再训练上千万次。

2. 神经网络训练的结果有对的也有错的，如果是错误的结果，将被当做非常宝贵的经验，那么是**如何从经验中学习的呢？**
   就是对比正确答案和错误答案之间的区别，然后把这个区别**反向的传递**回去，对每个相应的神经元进行一点点的改变。那么下一次在训练的时候就可以用已经改进一点点的神经元去得到稍微准确一点的结果。

3. **神经网络是如何训练的呢？**每个神经元都有属于它的**激活函数**，用这些函数给计算机一个刺激行为。

   ![image-20200929111309354](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7ckzquwqj30wu0j4aus.jpg)

   在第一次给计算机看猫的图片的时候，只有部分的神经元被激活，被激活的神经元所传递的信息是对输出结果最有价值的信息。如果输出的结果被判定为是狗，也就是说是错误的了，那么就会修改神经元，一些容易被激活的神经元会变得迟钝，另外一些神经元会变得敏感。这样一次次的训练下去，所有神经元的参数都在被改变，它们变得对真正重要的信息更为敏感。

   ![image-20200929111503409](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cmzoln8j311y0jeh8g.jpg)

   ![image-20200929111523738](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7cnbzv6pj311q0isaxd.jpg)

   代码及更多内容参考：https://www.jianshu.com/p/e112012a4b2d

## 卷积神经网络 CNN（Convolutional Neural Network）

卷积神经网络不再是对每个像素的输入信息做处理了，而是图片上每一小块像素区域进行处理，这种做法加强了图片信息的连续性，使得神经网络能看到图形，而非一个点。

这种做法同时也加深了神经网络对图片的理解。具体来说：

1. 卷积神经网络有一个批量过滤器，持续不断的在图片上滚动收集图片里的信息，每一次收集的时候都只是收集一小块像素区域，然后把收集来的信息进行整理，这时候整理出来的信息有了一些实际上的呈现，比如这时的神经网络能看到一些边缘的图片信息。
2. 然后再以同样的步骤，用类似的批量过滤器扫过产生的这些边缘信息，神经网络从这些边缘信息里面总结出更高层的信息结构，比如说总结的边缘能够画出眼睛，鼻子等等。
3. 再经过一次过滤，脸部的信息也从这些眼睛鼻子的信息中被总结出来。
4. 最后我们再把这些信息套入几层普通的全连接神经层进行分类，这样就能得到输入的图片能被分为哪一类的结果了。

![image-20200929113820427](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7db7koufj30wy0gg7bo.jpg)

具体说说图片是如何被卷积的。上面是一张猫的图片（以彩色照片为例）:

1. 过滤器就是影像中不断移动的东西，它不断在图片收集小批小批的像素块，收集完所有信息后，输出的值我们可以理解成是一个高度更高，长和宽更小的“图片”。这个图片里就能包含一些边缘信息。
2. 然后以同样的步骤再进行多次卷积，将图片的长宽再压缩，高度再增加，就有了对输入图片更深的理解。
3. 将压缩、增高的信息嵌套在普通的分类神经层上，我们就能对这种图片进行分类了。

> 图片有长，宽，高 三个参数。这里图片的高指的是计算机用于产生颜色使用的信息。如果是黑白照片的话，高的单位就只有1，如果是彩色照片，就可能有红绿蓝三种颜色的信息，这时的高度为3。

### 池化（pooling）

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7dib9elrj30lq0ciq6n.jpg" alt="image-20200929114510803" style="zoom:60%;" />

研究发现，在每一次卷积的时候，神经层可能会无意地丢失一些信息。这时，池化 (pooling) 就可以很好地解决这一问题。

**池化是一个筛选过滤的过程**，能将 layer 中有用的信息筛选出来，给下一个层分析。同时也减轻了神经网络的计算负担。也就是说在卷积的时候，我们不压缩长宽，尽量地保留更多信息，压缩的工作就交给池化了，这样的一项附加工作能够很有效的提高准确性。

## 循环神经网络 RNN（Recurrent Neural Network）

**RNN 是用来处理序列数据的神经网络**。那我们如何让数据间的关联被 NN 加以分析呢？

人类分析各种事物关联的最基本方式就是记住之前发生的事情。那我们让神经网络也具备这种记住之前发生的事的能力：

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7e9ibptvj30wo0guqpa.jpg" alt="image-20200929121118487" style="zoom:50%;" />

1. 在分析 Data0 的时候，我们把分析结果存入记忆。
2. 然后当分析 Data1 的时候，NN会产生新的记忆，但是新记忆和老记忆是没有联系的。我们就简单的把老记忆调用过来，一起分析。
3. 如果继续分析更多的有序数据，RNN就会把之前的记忆都累积起来，一起分析。

### LSTM RNN 循环神经网络（LSTM）

#### RNN 的弊端

之前我们说过，RNN 是在有顺序的数据上进行学习的。为了记住这些数据，RNN 会像人一样产生对先前发生事件的记忆。不过一般形式的 RNN 就像一个老爷爷，有时候比较健忘。为什么会这样呢？

具体原因参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/LSTM/

#### LSTM

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7ehfrgfij30sm0ni1kx.jpg" alt="image-20200929121855417" style="zoom:40%;" />

LSTM 就是为了解决这个问题而诞生的。LSTM 和普通 RNN 相比多出了三个控制器：输入控制、输出控制、忘记控制。 LSTM RNN 内部的情况如上图所示。

它多了一个 **控制全局的记忆**，我们用粗线代替。为了方便理解，我们把粗线想象成电影或游戏当中的 主线剧情，而原本的 RNN 体系就是 分线剧情。三个控制器都是在原始的 RNN 体系上。

1. 先看 输入方面：如果此时的分线剧情对于剧终结果十分重要，输入控制就会**将这个分线剧情按重要程度写入主线剧情进行分析**；
2. 再看 忘记方面：如果此时的分线剧情更改了我们对之前剧情的想法，那么忘记控制就会将之前的某些主线剧情忘记，按比例替换成现在的新剧情。所以**主线剧情的更新就取决于输入 和忘记 控制**。
3. 最后 输出方面：输出控制会**基于目前的主线剧情和分线剧情判断要输出的到底是什么**。

基于这些控制机制，LSTM 就像延缓记忆衰退的良药，可以带来更好的结果。

## 生成对抗网络（GAN）

神经网络分很多种，有普通的前向传播神经网络、有分析图片的 CNN 卷积神经网络、有分析序列化数据，比如语音的 RNN 循环神经网络。这些神经网络都是用来输入数据，得到想要的结果，我们看中的是这些神经网络能很好的将数据与结果通过某种关系联系起来。

但是还有另外一种形式的神经网络，它不是用来把数据对应上结果的，而是“凭空”捏造结果，这就是我们要说的生成网络。GAN 就是其中的一种形式。那么 GAN 是怎么做到的呢? 当然这里的“凭空”并不是什么都没有的空盒子，而是**一些随机数**。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7jg5b87cj30wy0h2hc0.jpg" alt="image-20200929151040278" style="zoom:50%;" />

Generator 会根据随机数来生成有意义的数据，Discriminator 会学习如何判断哪些是真实数据，哪些是生成数据，然后将学习的经验反向传递给 Generator，让 Generator 能根据随机数生成更像真实数据的数据。

## 自编码（Autoencoder）

自编码是一种神经网络的形式，是用神经网络进行非监督形式的学习。

### 压缩与解压

有一个神经网络，它在做的事情是：接收一张图片，然后 给它打码，最后 再从打码后的图片中还原。

图片其实是经过了压缩，再解压的这一道工序。当压缩的时候，原有的图片质量被缩减，解压时用信息量小却包含了所有关键信息的文件恢复出原本的图片。为什么要这样做呢？

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7hym8wn5j30ww0hi1kx.jpg" alt="image-20200929141914201" style="zoom: 50%;" />

原因是：有时神经网络要接受大量的输入信息，比如输入信息是高清图片时，输入信息量可能达到上千万，让神经网络直接从上千万个信息源中学习是一件很吃力的工作。
所以，何不压缩一下，提取出原图片中的最具代表性的信息，缩减输入信息量，再把缩减过后的信息放进神经网络学习，这样学习起来就简单轻松了。

所以，自编码就能在这时发挥作用。通过将原数据白色的X 压缩，解压 成黑色的X，然后通过对比黑白 X ，求出预测误差，进行反向传递，逐步提升自编码的准确性。训练好的自编码中间这一部分就是能总结原数据的精髓。
可以看出，从头到尾，我们只用到了输入数据 X，并没有用到 X 对应的数据标签，所以也可以说**自编码是一种非监督学习**，到了真正使用自编码的时候通常只会用到自编码前半部分。

### 编码器 Encoder

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7j1affh0j30pk0ms1kx.jpg" alt="image-20200929145620818" style="zoom:40%;" />

这部分也叫作 encoder 编码器。编码器能得到原数据的精髓，然后我们只需要再创建一个小的神经网络学习这个精髓的数据，不仅减少了神经网络的负担，而且同样能达到很好的效果。

### 解码器 Decoder

解码器在训练的时候是要将精髓信息解压成原始信息，那么这就提供了一个解压器的作用，甚至我们可以认为是一个生成器 (类似于GAN)。那做这件事的一种特殊自编码叫做 variational autoencoders。

## 梯度下降（Gradient Descent）

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7jsq7lsyj30x60h4tx3.jpg" alt="image-20200929152246502" style="zoom:50%;" />

神经网络中的误差方程 (Cost Function)是用来计算预测出来的和我们实际中的值有多大差别。在预测数值的问题中，我们常用平方差 (Mean Squared Error) 来代替。我们简化一下这个方程，W是我们神经网络中的参数，x、y 都是我们的数据，因为 x、y 都是实实在在的数据点，在这个假设情况中，是多少都无所谓，然后我们令x=1，y=0再继续简化一下，(注意，这个过程在在数学中并不正确，只是为了看效果)。

假设我们初始化的 W 在图中蓝点这个位置，而这个位置的斜率是这条线，这也就是梯度下降中的梯度。我们从图中可以看出，Cost 误差最小的时候正是这条 cost 曲线最低的地方，不过在蓝点的 W 却不知道这件事情，他目前所知道的就是梯度线为自己在这个位置指出的一个下降方向，我们就要朝着这个蓝色梯度的方向下降一点点，再做一条切线，发现我还能下降，那我就朝着梯度的方向继续下降，这时，再展示出现在的梯度，因为梯度线已经躺平了，我们已经指不出哪边是下降的方向了，所以这时我们就找到了 W 参数的最理想值。

简而言之，就是找到梯度线躺平的点. 可是神经网络的梯度下降可没这么简单。

![image-20200929152902246](https://tva1.sinaimg.cn/large/007S8ZIlly1gj7jz9de7lj30wy0danco.jpg)

神经网络中的 W 可不止一个，如果只有一个 W，我们就能画出之前那样的误差曲线，如果有两个 W 也简单，我们可以用一个3D 图来展示，可是超过3个 W，我们就没办法很好的可视化出来。

## 迁移学习

有时候面对类似的任务时，我们希望能够借鉴已有的资源。这就好比：Google 和百度的关系、Facebook 和人人的关系、KFC 和 麦当劳的关系。同一类型的事业，不用自己完全从头做，借鉴对方的经验，往往能节省很多时间。有这样的思路，我们也能偷偷懒，不用花时间重新训练一个无比庞大的神经网络，借鉴借鉴一个已经训练好的神经网络就行。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7kfb6894j30x40gs1kx.jpg" alt="image-20200929154426607" style="zoom:50%;" />

比如这样的一个神经网络，我花了两天训练完之后，它已经能正确区分图片中具体描述的是男人，女人还是眼镜。说明这个神经网络已经具备对图片信息一定的理解能力，这些理解能力就以参数的形式存放在每一个神经节点中。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7kl9mvcij30x80hi1kx.jpg" alt="image-20200929155012159" style="zoom:50%;" />

不巧，领导下达了一个紧急任务，要求今天之内训练出来一个预测图片里实物价值的模型。这时我们就可以用到迁移学习：

1. 因为这个训练好的模型中已经有了一些对图片的理解能力，而模型最后输出层的作用是分类之前的图片，对于现在计算价值的任务是用不到的，所以我将最后一层替换掉，变为服务于现在这个任务的输出层；
2. 接着只训练新加的输出层，让理解力保持始终不变。前面的神经层庞大的参数不用再训练，节省了很多时间。

> 但并不是所有时候我们都需要迁移学习。比如神经网络很简单，相比起计算机视觉中庞大的 CNN 或者语音识别的 RNN，训练小的神经网络并不需要特别多的时间，我们完全可以直接重头开始训练。从头开始训练也是有好处的。
>
> 如果固定住之前的理解力，或者使用更小的学习率来更新借鉴来的模型，就变得有点像认识一个人时的第一印象，如果迁移前的数据和迁移后的数据差距很大，或者说我对于这个人的第一印象和后续印象差距很大，我还不如不要管我的第一印象。同理，这时迁移来的模型并不会起多大作用，还可能干扰我后续的决策。

# 神经网络机器技巧

## 检验神经网络（Evaluation）

介绍在做好了属于自己的神经网络之后，应该如何来评价自己的神经网络，从评价当中如何改进我们的神经网络。

在神经网络的训练当中，神经网络可能会因为各种各样的问题，出现学习的效率不高，或者是因为干扰太多，学到最后并没有很好的学到规律。而这其中的原因可能是多方面的，可能是数据问题、学习效率 等参数问题。

### Training and Test data

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7lrfbfykj30vc0hy4qp.jpg" alt="image-20200929163039813" style="zoom:50%;" />

为了检验、评价神经网络，避免和改善这些问题，我们通常会把收集到的数据分为训练数据 和 测试数据，一般用于训练的数据可以是所有数据的70%，剩下的30%可以拿来测试学习结果。

### 误差曲线

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7lrtdlz0j30wg0jaqma.jpg" alt="image-20200929163102349" style="zoom:50%;" />

接着，对于神经网络的评价基本上是基于这30%的测试数据。评价机器学习可以从误差这个值开始，随着训练时间的变长，优秀的神经网络能预测到更为精准的答案，预测误差也会越少，到最后能够提升的空间变小，曲线也趋于水平。

### 准确度曲线

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7m92ybxaj30x20iyttu.jpg" alt="image-20200929164741506" style="zoom:50%;" />

同样，除了误差曲线，我们可以看他的精确度曲线。最好的精度是趋向于100%精确。比如在神经网络的分类问题中，100个样本中，我有90张样本分类正确，那就是说我的预测精确度是90%。

不过，不知道大家有没有想过对于回归的问题呢？怎样看预测值是连续数字的精确度? 这时，我们可以引用 R2 分数在测量回归问题的精度。R2给出的最大精度也是100%，所以分类和回归就都有的统一的精度标准。除了这些评分标准，我们还有很多其他的标准，比如 F1 分数 ，用于测量不均衡数据的精度。

### 正规化

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj7maz1e4cj30wm0ma1hv.jpg" alt="image-20200929164930356" style="zoom:50%;" />

有时候，意外是猝不及防的，比如有时候我们明明每一道作业习题都会做，可是考试分数为什么总是比作业分数低许多？原来，我们只复习了作业题，并没有深入，拓展研究作业反映出来的知识。这件事情发生在机器学习中，我们就叫做**过拟合**。我们在回到误差曲线，不过这时我们也把训练误差画出来，红色的是训练误差，黑色的是测试误差。训练时的误差比测试的误差小，神经网络虽然学习到了知识，但是对于平时作业太过依赖，到了考试的时候，却不能随机应变，没有成功的把作业的知识扩展开来。在机器学习中，解决过拟合也有很多方法 ，比如 l1 / l2 正规化、dropout 方法。

### 交叉验证

<img src="/Users/didi/Library/Application Support/typora-user-images/image-20200929165200107.png" alt="image-20200929165200107" style="zoom:50%;" />

神经网络也有很多参数，我们怎么确定哪样的参数能够更有效的解决现有的问题呢？

这时，交叉验证 就是最好的途径了。交叉验证不仅仅可以用于神经网络的调参，还能用于其他机器学习方法的调参。
同样是选择你想观看的误差值或者是精确度，不过横坐标不再是学习时间，而是你要测试的某一参数 (比如说神经网络层数)。我们逐渐增加神经层，然后对于每一个不同层结构的神经网络求出最终的误差或精度，画在图中。
我们知道，神经层越多，计算机所需要消耗的时间和资源就越多，所以我们只需要找到那个能满足误差要求，又节约资源的层结构。比如说误差在0.005以下都能接受 ，那我们就可以采用30层的神经网络结构。

## 特征标准化（Feature Normalization）

在机器学习中，如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致机器并不能像我们期望的那样，从其他特征中学习。为了避免这种情况，在机器学习训练之前，先对数据预先处理一下：取值跨度大的特征数据浓缩一下，跨度小的扩展一下，使得他们的跨度尽量统一。

通常用于 特征标准化的途径有两种：

1. min max normalization：它会将所有特征数据按比例缩放到 0-1 的这个取值区间，有时也可以是 -1到1 的区间；
2. standard deviation normalization：它会将所有特征数据缩放成 平均值为0，方差为1。

使用这些标准化手段，我们不仅可以快速推进机器学习的学习速度，还可以避免机器学习 学得特扭曲。

## 选择好特征（Good Feature）

1. 避免无意义的信息
2. 避免重复性的信息
3. 避免复杂的信息

更多参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/choose-feature/

## 激励函数（Activation Function）

激励函数是为了解决我们日常生活中不能用线性方程所概括的问题。

如何在神经网络中达成我们描述非线性的任务？

我们可以把整个网络简化成这样一个式子：y = Wx，W 就是我们要求的参数，y 是预测值，x 是输入值。用这个式子我们很容易就能描述一个线性问题，因为 W 求出来可以是一个固定的数。不过这似乎并不能让这条直线变得扭起来 ，这时候就需要激励函数来“掰弯”它。

![image-20200929200559408](https://i.loli.net/2020/09/29/yPpXzMF4YaCGnmd.png)

这里的 AF 就是指的激励函数。它其实就是另外一个非线性函数，比如说relu，sigmoid，tanh。将这些掰弯利器嵌套在原有的结果之上，强行把原有的线性结果给扭曲了，使得输出结果 y 也有了非线性的特征。举个例子，比如我使用了 relu 这个掰弯利器，如果此时 Wx 的结果是1，y 还将是1，不过 Wx 为-1的时候，y 不再是-1，而会是0。

### 如何选择激励函数？

当你的神经网络层只有两三层，不是很多的时候，对于隐藏层，使用任意的激励函数，随便掰弯是可以的，不会有特别大的影响。不过，当你使用特别多层的神经网络，在掰弯的时候，往往不得随意选择利器，因为这会涉及到梯度爆炸，梯度消失的问题。

在少量层结构中，我们可以尝试很多种不同的激励函数. 在卷积神经网络 Convolutional neural networks 的卷积层中，推荐的激励函数是 relu；在循环神经网络中 recurrent neural networks，推荐的是 tanh 或者是 relu 。

## 欠拟合、过拟合（Overfitting）

### 欠拟合及解决方法

欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据。

解决方法：

1. **添加其他特征项**。有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。
2. **添加多项式特征**。这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。
3. **减少正则化参数**。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。

### 过拟合及解决方法

通俗一点地来说过拟合就是模型把数据学习的太彻底，以至于把噪声数据的特征也学习到了，这样就会导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差。

解决方法：

1. **重新清洗数据**。导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。

2. **增大数据的训练量**。还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。

3. **采用正则化方法**。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用**L2正则**。(具体原因参考：https://blog.csdn.net/willduan1/article/details/53070777)

4. **采用dropout方法**。这个方法在神经网络里面很常用。dropout方法是ImageNet中提出的一种方法，通俗一点讲就是dropout方法在训练的时候让神经元以一定的概率不工作。具体看下图：

   ![image-20200929204857923](https://i.loli.net/2020/09/29/qbrSLJvI8N7xRlu.png)

如上图所示，左边a图是没用用dropout方法的标准神经网络，右边b图是在训练过程中使用了dropout方法的神经网络，即**在训练时候以一定的概率p来跳过一定的神经元**。

## 加速神经网络的训练

包括以下几种模式:

- Stochastic Gradient Descent (SGD)
- Momentum
- AdaGrad
- RMSProp
- Adam（常用）

具体参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/speed-up-learning/

## 处理不均衡数据

不均衡的数据预测起来很简单：永远都猜多的那一方面准没错。所以机器学到最后每次都预测多数派，不具有很好的泛化性。解决的方法：、

1. 获取更多数据

2. 更换评判方式

   <img src="https://i.loli.net/2020/09/29/ULyFurnkpgiVb3s.png" alt="image-20200929210507037" style="zoom:80%;" />

   通常，我们会用到 准确率 accuracy，或者误差 cost来判断机器学习的成果。
   可是这些评判方法在不均衡数据面前，高的准确率和低的误差变得没那么重要。所以我们得换一种方式评判。
   通过 confusion matrix 来计算 precision 和 recall，然后通过 precision 和 recall 再计算 F1 分数.这种方式能成功地区分不均衡数据，给出更好的评判分数。

3. 重组数据

   重新组合不均衡数据，使之均衡。
   方式一：复制或者合成少数部分的样本，使之和多数部分差不多数量；
   方式二：砍掉一些多数部分，使两者数量差不多。

4. 使用其他机器学习方法

   如果使用的机器学习方法像神经网络等，在面对不均衡数据时，通常是束手无策。不过有些机器学习方法，像决策树，decision trees 就不会受到不均衡数据的影响。

5. 修改算法

## 批标准化（Batch Normalization）

## L1 / L2 正规化（Regularization）

# 强化学习

## 机器学习、深度学习、强化学习、深度强化学习

![image-20200928233034231](https://tva1.sinaimg.cn/large/007S8ZIlly1gj6sa1q9i8j310k0j4k2p.jpg)

<u>机器学习</u>：一切通过优化方法挖掘数据中规律的学科。

<u>深度学习</u>：一切运用了神经网络作为参数结构进行优化的机器学习算法。

<u>强化学习</u>：不仅能利用现有数据，还可以通过对环境的探索获得新数据，并利用新数据循环往复地更新迭代现有模型的机器学习算法。学习是为了更好地对环境进行探索，而探索是为了获取数据进行更好的学习。

<u>深度强化学习</u>：一切运用了神经网络作为参数结构进行优化的强化学习算法。

从大的角度讲，**机器学习是包括深度学习和强化学习的**。

强化学习和深度学习的主要区别在于：

1. **深度学习的训练样本是有标签的，强化学习的训练是没有标签的**，它是通过环境给出的奖惩来学习；
2. **深度学习的学习过程是静态的，强化学习的学习过程是动态的**。这里静态与动态的区别在于是否会与环境进行交互，深度学习是给什么样本就学什么，而强化学习是要和环境进行交互，再通过环境给出的奖惩来学习；
3. **深度学习解决的更多是感知问题，强化学习解决的主要是决策问题**。因此有监督学习更像是五官，而强化学习更像大脑。

> 应用方面
>
> -- 较传统的机器学习（包括lr svm decision tree GBDT RF  etc.）多用于数据挖掘、数据分析和预测等领域；
> -- 深度学习最广泛的应用是图像处理和NLP了；
> -- 强化学习实际应用目前主要包括AI游戏（如Atari），推荐系统（如阿里家的），机器人控制相关（如Ng的无人机飞行）。

## 强化学习算法的分类

### 不理解环境(Model-Free RL) & 理解环境(Model-Based RL)

1. Model-Free RL

   不尝试去理解环境，环境给了我们什么就是什么。

2. Model-Based RL

   这里的model就是用模型来表示环境，理解了环境也就是学会了一个模型来代表环境。

> Model-Free 与 Model-Based 区别：
>
> 1. Model-Based 比 Model-Free 多了一个**虚拟环境**(为现实世界建模)
>
> 2. Model-Based 比 Model-Free 多了更多的**“想象力”**
>
>    Model-Free 只能一步一步等待真实世界的反馈，再根据反馈采取下一步的行动；
>
>    Model-Based 可以通过“想象”来预判到接下来发生的所有情况，然后根据想象中的情况选择最好的那种，并根据这种情况来采取下一步的策略。

### 基于概率(Policy-Based RL) & 基于价值(Value-Based RL)

1. Policy-Based RL

   通过分析所处环境，直接分析出下一步采取各种行动的概率，然后根据概率采取行动，所以所有动作都可以被选中，只是可能性不同。

2. Value-Based RL

   通过分析所处环境，直接分析出下一步采取各种行动的价值，然后根据最高价值采取行动。与Policy-Based 相比**决策更为确定**，只选价值最高的。

> 对于连续动作，无法基于价值(Value-Based)进行动作的选择，但是可以基于概率分布(Policy-Based)在连续的动作中选择特定的动作。

### 回合更新(Monte-Carlo update) & 单步更新(Temporal-Difference update)

1. Monte-Carlo update

   训练开始 -- > 训练结束 -- > 对该回合进行复盘与更新

2. Temporal-Difference update

   训练开始 -- > 单步更新  -- > 单步更新  -- > ... -- > 训练结束

### 在线学习(Online-Learning) & 离线学习(Offline-Learning)

1. Online-Learning

   一个数据点训练完了直接更新权重（而不是一个batch）。

   在线算法按照顺序处理数据，它们产生一个模型，并在把这个模型放入实际操作中，而**不需要在一开始就提供完整的的训练数据集。随着更多的实时数据到达，模型会在操作中不断地更新。**

2. Offline-Learning

   一个batch训练完才更新权重。

   在离线学习中，所有的训练数据在模型训练期间必须是可用的。只有训练完成了之后，模型才能被拿来用。简而言之，**先训练，再用模型，不训练完就不用模型。**

 对比图

<img src="https://img-blog.csdnimg.cn/2019110915213854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjI2NzYxNQ==,size_16,color_FFFFFF,t_70" alt="离线模式选择(左)与在线模式选择(右)" style="zoom: 80%;" />

> Online-Learning & Offline-Learning 也叫 On-Policy & Off-Policy
>
> 更多参考：https://blog.csdn.net/weixin_42267615/article/details/102973252?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf



更多参考：https://mofanpy.com/tutorials/machine-learning/ML-intro/